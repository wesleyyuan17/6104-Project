@inproceedings{Cakmak2020,
	author = {Cakmak, Sait and Astudillo Marban, Raul and Frazier, Peter and Zhou, Enlu},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {20130--20141},
	publisher = {Curran Associates, Inc.},
	title = {Bayesian Optimization of Risk Measures},
	url = {https://proceedings.neurips.cc/paper/2020/file/e8f2779682fd11fa2067beffc27a9192-Paper.pdf},
	volume = {33},
	year = {2020}
}

@article{Wilkens2019,
	author = {Sascha Wilkens},
	title = {Machine Learning in Risk Measurement: Gaussian Process Regression for Value-at-Risk and Expected Shortfall},
	journal = {Journal of Risk Management in Financial Institutions},
	volume = {12},
	pages = {374-383},
	year = {2019},
}

@book{Rasmussen2006,
	author = {Carl Edward Rasmussen and Christopher K. I. Williams},
	title = {Gaussian Processes for Machine Learning},
	year = {2006},
	publisher = {MIT Press}
}

@article{Farrel2007,
	author = {Todd Farrell and Andrew Correa},
	year = {2007},
	month = {01},
	title = {Gaussian Process Regression Models for Predicting Stock Trends}
}

@article{Park2007,
	author = {Cheol-Ho Park and Scott H. Irwin},
	title = {What Do We Know About the Profitability of Technical Analysis?},
	journal = {Journal of Economic Surveys},
	volume = {21},
	number = {4},
	pages = {786-826},
	doi = {https://doi.org/10.1111/j.1467-6419.2007.00519.x},
	year = {2007}
}

@article{Silver2017,
	author = {David Silver and Julian Schrittwieser and Karen Simonyan and Ioannis Antonoglou and Aja Huang and Arthur Guez and Thomas Hubert and Lucas Baker and Matthew Lai and Adrian Bolton and Yutian Chen and Timothy Lillicrap and Fan Hui and Laurent Sifre and George van den Driessche and Thore Graepel and Demis Hassabis},
	title = {Mastering the Game of Go without Human Knowledge},
	journal = {Nature},
	volume = {550},
	pages = {354-359},
	year = {2017}
}

@book{SuttonBarto,
	author = {Richard S. Sutton and Andrew G. Barto},
	title = {Reinforcement Learning: An Introduction},
	edition = {2nd},
	year = {2018},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA}
}

@article{GoogleAtari,
	author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
	title = {Playing Atari with Deep Reinforcement Learning},
	journal = {CoRR},
	volume = {abs/1312.5602},
  	year = {2013}
}

@article{AlphaGo,
	author = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
	title = {Mastering the game of Go with deep neural networks and tree search},
	journal = {Nature},
	volume  = {529},
	year = {2016},
	pages = {484–489}
}

@article{Wang2019,
	author = {Haoran Wang and Xun Zhou},
	year = {2019},
	month = {07},
	title = {Large Scale Continuous-Time Mean-Variance Portfolio Allocation via Reinforcement Learning},
	journal = {SSRN Electronic Journal},
	doi = {10.2139/ssrn.3428125}
}

@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@inproceedings{gardner2018gpytorch,
  title={GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration},
  author={Gardner, Jacob R and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{Dempster2006,
	title = {An automated FX trading system using adaptive reinforcement learning},
	author = {M.A.H. Dempster and V. Leemans},
	journal = {Expert Systems with Applications},
	volume = {30},
	number = {3},
	pages = {543-552},
	year = {2006},
	note = {Intelligent Information Systems for Financial Engineering},
	issn = {0957-4174},
	doi = {https://doi.org/10.1016/j.eswa.2005.10.012},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417405003015},
}

@article{Yang2020,
	author = {Hongyang Yang and Xiao-Yang Liu and Shan Zhong and Anwar Walid},
	year = {2020},
	month = {01},
	pages = {},
	title = {Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy},
	journal = {SSRN Electronic Journal},
	doi = {10.2139/ssrn.3690996}
}

@article{Deng2017,
  author = {Yue Deng and Feng Bao and Youyong Kong and Zhiquan Ren and Qionghai Dai},
  journal = {IEEE Transactions on Neural Networks and Learning Systems}, 
  title = {Deep Direct Reinforcement Learning for Financial Signal Representation and Trading}, 
  year = {2017},
  volume = {28},
  number = {3},
  pages = {653-664},
  doi = {10.1109/TNNLS.2016.2522401}
}

@article{Ghavamzadeh2016,
	author = {Mohammad Ghavamzadeh and Shie Mannor and Joelle Pineau and Aviv Tamar},
	title = {Bayesian Reinforcement Learning: A Survey},
	year = {2015},
	month = {11},
	publisher = {Now Publishers Inc.},
	address = {Hanover, MA, USA},
	volume = {8},
	number = {5–6},
	issn = {1935-8237},
	url = {https://doi.org/10.1561/2200000049},
	doi = {10.1561/2200000049},
	journal = {Found. Trends Mach. Learn.},
	pages = {359–483},
	numpages = {125}
}

% Q-learning regret bound
@misc{Jin18QLearning,
    title = {Is Q-learning Provably Efficient?},
    author = {Chi Jin and Zeyuan Allen-Zhu and Sebastien Bubeck and Michael I. Jordan},
    year = {2018},
    eprint = {1807.03765},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

% TD learning converges
@article{Jaakkola94, 
	author = {Tommi Jaakkola and Michael I. Joradn and Satinder P. Singh}, 
	journal = {Neural Computation}, 
	title = {On the Convergence of Stochastic Iterative Dynamic Programming Algorithms}, 
	year = {1994}, 
	volume = {6}, 
	number = {6}, 
	pages = {1185-1201},
}

@article{Schulman2017,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Silver2014,
	author = {David Silver and Guy Lever and Nicolas Heess and Thomas Degris and Daan Wierstra and Martin Riedmiller},
	year = {2014},
	month = {06},
	pages = {},
	title = {Deterministic Policy Gradient Algorithms},
	volume = {1},
	journal = {31st International Conference on Machine Learning, ICML 2014}
}

@misc{Lillicrap2019,
	title={Continuous control with deep reinforcement learning}, 
	author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
	year={2019},
	eprint={1509.02971},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{Mnih2016A2C,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  archivePrefix = {arXiv},
  eprint    = {1602.01783},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



% policy iteration convergence
@article{Bertsekas15,
  author = {Dimitri P. Bertsekas},
  title = {Value and Policy Iteration in Optimal Control and Adaptive Dynamic
  Programming},
  journal = {CoRR},
  volume = {abs/1507.01026},
  year = {2015},
  url = {http://arxiv.org/abs/1507.01026},
  archivePrefix = {arXiv},
  eprint = {1507.01026},
  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},
  biburl = {https://dblp.org/rec/journals/corr/Bertsekas15a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inbook{Bertsekas95,
	author = {Dimitri P. Bertsekas},
	year = {1995},
	month = {01},
	pages = {},
	title = {Dynamic Programming and Optimal Control},
	volume = {1},
	publisher = {Athena Scientific},
}

% lower bound of RL w/ generative model
@inproceedings{VILowerBound,
	author = {Mohammad Gheshlaghi Azar and R\'{e}mi Munos and Hilbert J. Kappen},
	title = {On the Sample Complexity of Reinforcement Learning with a Generative Model},
	year = {2012},
	isbn = {9781450312851},
	publisher = {Omnipress},
	address = {Madison, WI, USA},
	booktitle = {Proceedings of the 29th International Conference on Machine Learning},
	pages = {1707–1714},
	numpages = {8},
	location = {Edinburgh, Scotland},
	series 	= {ICML’12}
}

% convergence rate of value iteration
@inproceedings{Littman96,
	author = {Michael Littman and Csaba Szepesvári},
	year = {1996},
	month = {01},
	pages = {310-318},
	title = {A Generalized Reinforcement-Learning Model: Convergence and Applications.},
	booktitle = {Proceedings of the 13th International Conference on Machine Learning}
}

% proves Q-learning converges to optimal action-values with probability 1
@article{WatkinsDayan,
	author = {Christopher J.C.H. Watkins and Peter Dayan},
	title = {Q-Learning},
	journal = {Machine Learning},
	volume = {8},
	pages = {272-292},
	year = {1992}
}